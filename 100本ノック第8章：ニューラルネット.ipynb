{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "100本ノック第8章：ニューラルネット.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ReXFklRD1oRPAunnriPhSyot3fVvTe59",
      "authorship_tag": "ABX9TyNT40vi8oFznCyp+yY6qPPL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 前準備"
      ],
      "metadata": {
        "id": "qKtbIodfAzr9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qtm3HCqh-cCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fc9300-a895-4bc1-8daa-ac5ab6ad6bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-04 11:57:54--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29224203 (28M) [application/x-httpd-php]\n",
            "Saving to: ‘NewsAggregatorDataset.zip’\n",
            "\n",
            "NewsAggregatorDatas 100%[===================>]  27.87M  13.3MB/s    in 2.1s    \n",
            "\n",
            "2022-03-04 11:57:57 (13.3 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203/29224203]\n",
            "\n",
            "Archive:  NewsAggregatorDataset.zip\n",
            "  inflating: 2pageSessions.csv       \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "  inflating: newsCorpora.csv         \n",
            "  inflating: __MACOSX/._newsCorpora.csv  \n",
            "  inflating: readme.txt              \n",
            "  inflating: __MACOSX/._readme.txt   \n"
          ]
        }
      ],
      "source": [
        "# データセットのダウンロード\n",
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
        "! unzip NewsAggregatorDataset.zip\n",
        "# 読込時のエラー回避のためダブルクォーテーションをシングルクォーテーションに置換\n",
        "!sed -e 's/\"/'\\''/g' ./newsCorpora.csv > ./newsCorpora_re.csv\n",
        "from gensim.models import KeyedVectors\n",
        "# 学習済み単語ベクトルのロード\n",
        "model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Colab Notebooks/nlp100/chapter8/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 70. 単語ベクトルの和による特徴量\n",
        "# ============\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/newsCorpora.csv', sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
        "\n",
        "# df.locは単独および複数の要素の値を選択、取得、変更が可能\n",
        "# isinはbool型を返す\n",
        "df1 = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
        "\n",
        "# データの分割 stratifyを設定することで訓練データとテストデータの指定した中身の割合を同じにすることができる\n",
        "train, temp = train_test_split(df1, test_size=0.2, shuffle=True, random_state=0, stratify=df1['CATEGORY'])\n",
        "test, valid = train_test_split(temp, test_size=0.5, shuffle=True, random_state=0, stratify=temp['CATEGORY'])\n",
        "\n",
        "# データの保存\n",
        "! mkdir -p /content/data/\n",
        "train.to_csv('/content/data/train.txt', sep=\"\\t\", index=False)\n",
        "test.to_csv('/content/data/test.txt', sep=\"\\t\", index=False)\n",
        "valid.to_csv('/content/data/valid.txt', sep=\"\\t\", index=False)\n",
        "\n",
        "# print(train['CATEGORY'].value_counts())\n",
        "# print(valid['CATEGORY'].value_counts())\n",
        "# print(test['CATEGORY'].value_counts())"
      ],
      "metadata": {
        "id": "ldPY6_hcA2-2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import string\n",
        "def transform_w2v(text):\n",
        "    # maketransの説明  maketrans(変換前文字列, 変換後文字列, 削除対象文字列)\n",
        "    # string.punctuationの中身  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "    table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "    words = text.translate(table).split()  \n",
        "    vec = [model[word] for word in words if word in model] \n",
        "    return torch.tensor(sum(vec) / len(vec))\n",
        "\n",
        "def make_vec(input, features_output, labels_output):\n",
        "    with open(input, 'r') as f:\n",
        "        category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "        data  = pd.read_csv(input, sep='\\t')\n",
        "        sentences = data[\"TITLE\"]\n",
        "        labels = data[\"CATEGORY\"]\n",
        "\n",
        "        X = torch.stack([transform_w2v(text) for text in sentences])\n",
        "        Y = torch.tensor(data[\"CATEGORY\"].map(category_dict))\n",
        "        torch.save(X, features_output)\n",
        "        torch.save(Y, labels_output)\n",
        "        return X, Y\n",
        "! mkdir -p /content/pytorch_data/\n",
        "X_train, Y_train = make_vec(\"/content/data/train.txt\", \"/content/pytorch_data/X_train.pt\", \"/content/pytorch_data/Y_train.pt\")\n",
        "X_valid, Y_valid = make_vec(\"/content/data/valid.txt\", \"/content/pytorch_data/X_valid.pt\", \"/content/pytorch_data/Y_valid.pt\")\n",
        "X_test , Y_test  = make_vec(\"/content/data/test.txt\" , \"/content/pytorch_data/X_test.pt\" , \"/content/pytorch_data/Y_test.pt\")"
      ],
      "metadata": {
        "id": "xXK-MyZFweDa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 71. 単層ニューラルネットワークによる予測\n",
        "# ============\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(300, 4, bias=False)\n",
        "        nn.init.normal_(self.fc.weight, 0.0, 1.0) # 正規乱数で重みを初期化\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.fc(x)\n",
        "        return y\n",
        "\n",
        "net = Net() # ネットワークのインスタンスを作成\n",
        "y_hat_1 = torch.softmax(net(X_train[:1]), dim=-1)\n",
        "print(y_hat_1)\n",
        "Y_hat = torch.softmax(net(X_train[:4]), dim=-1)\n",
        "print(Y_hat)"
      ],
      "metadata": {
        "id": "lRE96IQuA-f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f955c1d-5abc-41fc-ab7e-f9772c5ff3b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2455, 0.2214, 0.0554, 0.4777]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2455, 0.2214, 0.0554, 0.4777],\n",
            "        [0.0285, 0.4506, 0.4651, 0.0559],\n",
            "        [0.0457, 0.1363, 0.2585, 0.5594],\n",
            "        [0.0236, 0.3270, 0.2822, 0.3673]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 72. 損失と勾配の計算\n",
        "# ============\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "l_1 = criterion(net(X_train[:1]), Y_train[:1])  # 事例 x_1 の損失の計算\n",
        "net.zero_grad() # 勾配を初期化\n",
        "l_1.backward()  # 勾配を計算\n",
        "print(f'損失: {l_1:.4f}')\n",
        "print(f'勾配:\\n{net.fc.weight.grad}')\n",
        "\n",
        "l_1_4 = criterion(net(X_train[:4]), Y_train[:4]) # 事例 x_1 ～ x_4 の損失の計算\n",
        "net.zero_grad()\n",
        "l_1_4.backward()\n",
        "print(f'損失: {l_1_4:.4f}')\n",
        "print(f'勾配:\\n{net.fc.weight.grad}')\n",
        "\n",
        "# 損失の確認\n",
        "ans = [] \n",
        "for s,i in zip(torch.softmax(net(X_train[:4]), dim=-1),Y_train[:4]):\n",
        "    s = s.to('cpu').detach().numpy().copy()\n",
        "    ans.append(-np.log(s[i]))\n",
        "print(np.mean(ans))"
      ],
      "metadata": {
        "id": "YVkGb1dhA_8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9375f01b-db07-4829-a20b-e224e551e301"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失: 1.4045\n",
            "勾配:\n",
            "tensor([[ 0.1056, -0.0394,  0.0544,  ..., -0.0229, -0.0169,  0.0616],\n",
            "        [-0.0310,  0.0116, -0.0160,  ...,  0.0067,  0.0050, -0.0181],\n",
            "        [-0.0078,  0.0029, -0.0040,  ...,  0.0017,  0.0012, -0.0045],\n",
            "        [-0.0669,  0.0250, -0.0345,  ...,  0.0145,  0.0107, -0.0390]])\n",
            "損失: 2.5158\n",
            "勾配:\n",
            "tensor([[ 0.0652, -0.0227, -0.0069,  ..., -0.0288, -0.0246,  0.0257],\n",
            "        [-0.0253,  0.0043,  0.0069,  ...,  0.0131,  0.0137, -0.0091],\n",
            "        [-0.0067,  0.0127, -0.0138,  ...,  0.0122, -0.0100, -0.0018],\n",
            "        [-0.0332,  0.0057,  0.0138,  ...,  0.0036,  0.0210, -0.0148]])\n",
            "2.5158274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 73. 確率的勾配降下法による学習\n",
        "# ============\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# ランダムシード\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# バッチサイズ\n",
        "batch_size = 10\n",
        "\n",
        "# モデルをGPUへ転送\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = net.to(device)\n",
        "\n",
        "# Datasetの作成\n",
        "train = TensorDataset(X_train, Y_train)   \n",
        "valid = TensorDataset(X_valid, Y_valid)\n",
        "test  = TensorDataset(X_test,  Y_test)\n",
        "\n",
        "# 訓練用・検証用・評価用の各データをDataLoaderに格納\n",
        "train_loader = DataLoader(train, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(valid, batch_size)\n",
        "test_loader = DataLoader(test, batch_size)\n",
        "\n",
        "# 損失関数と最適化手法の選択\n",
        "criterion = nn.CrossEntropyLoss()   \n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01) \n",
        "\n",
        "# 訓練ループ（エポックごとに検証データの正解率を表示）\n",
        "max_epoch = 30\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    train_loss = 0\n",
        "    for x, t in train_loader:\n",
        "\n",
        "        # データをGPUへ転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 勾配を初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播\n",
        "        y = net(x)   # 2\n",
        "        loss = criterion(y, t)   # 3\n",
        "\n",
        "        # 学習状況の確認\n",
        "        # print(\"epoch: %d    loss: %.3f\" % (epoch+1, loss.item()))\n",
        "        train_loss += loss\n",
        "\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()   # 4\n",
        "        optimizer.step()  # 5\n",
        "    \n",
        "    print(\"epoch: %d    train_loss: %.3f\" % (epoch+1, train_loss/len(train_loader)))"
      ],
      "metadata": {
        "id": "rpuOde-1A_w0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "858ffc68-b261-43f3-ec0a-b9a4e2a81ed1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1    train_loss: 1.419\n",
            "epoch: 2    train_loss: 1.035\n",
            "epoch: 3    train_loss: 0.910\n",
            "epoch: 4    train_loss: 0.837\n",
            "epoch: 5    train_loss: 0.783\n",
            "epoch: 6    train_loss: 0.742\n",
            "epoch: 7    train_loss: 0.707\n",
            "epoch: 8    train_loss: 0.678\n",
            "epoch: 9    train_loss: 0.653\n",
            "epoch: 10    train_loss: 0.631\n",
            "epoch: 11    train_loss: 0.612\n",
            "epoch: 12    train_loss: 0.594\n",
            "epoch: 13    train_loss: 0.579\n",
            "epoch: 14    train_loss: 0.565\n",
            "epoch: 15    train_loss: 0.551\n",
            "epoch: 16    train_loss: 0.540\n",
            "epoch: 17    train_loss: 0.529\n",
            "epoch: 18    train_loss: 0.519\n",
            "epoch: 19    train_loss: 0.509\n",
            "epoch: 20    train_loss: 0.501\n",
            "epoch: 21    train_loss: 0.493\n",
            "epoch: 22    train_loss: 0.486\n",
            "epoch: 23    train_loss: 0.478\n",
            "epoch: 24    train_loss: 0.471\n",
            "epoch: 25    train_loss: 0.465\n",
            "epoch: 26    train_loss: 0.459\n",
            "epoch: 27    train_loss: 0.454\n",
            "epoch: 28    train_loss: 0.448\n",
            "epoch: 29    train_loss: 0.443\n",
            "epoch: 30    train_loss: 0.439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 74. 正解率の計算\n",
        "# ============\n",
        "# ラベルを格納するリスト↓\n",
        "labels1 = []\n",
        "labels2 = []\n",
        "\n",
        "def calc_acc(data_loader):\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "        accs = list()\n",
        "        for x, t in data_loader:\n",
        "            x = x.to(device)\n",
        "            t = t.to(device)\n",
        "            labels2.extend(t)\n",
        "\n",
        "            y = net(x)\n",
        "            loss += criterion(y, t).item()\n",
        "\n",
        "            label = torch.argmax(y, dim=1)\n",
        "            labels1.extend(label)\n",
        "            \n",
        "            acc = (label == t).sum() * 1.0 / len(t)\n",
        "            accs.append(acc)\n",
        "\n",
        "    return torch.tensor(accs).mean(), loss/len(data_loader)\n",
        "    \n",
        "\n",
        "# 訓練ループ（エポックごとに検証データの正解率を表示）\n",
        "max_epoch = 30\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for x, t in train_loader:\n",
        "\n",
        "        # データをGPUへ転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 勾配を初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播\n",
        "        y = net(x)   # 2\n",
        "        loss = criterion(y, t)   # 3\n",
        "\n",
        "        # 学習状況の確認\n",
        "        label = torch.argmax(y, dim=1)\n",
        "        acc = (label == t).sum() * 1.0 / len(t)\n",
        "        # print(\"epoch: %d    loss: %.3f    acc: %.3f\" % (epoch+1, loss.item(), acc))\n",
        "\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()   # 4\n",
        "        optimizer.step()  # 5\n",
        "    \n",
        "    # 検証データの性能を確認\n",
        "    val_acc, val_loss = calc_acc(val_loader)\n",
        "    print(\"epoch: %d    val_acc: %.3f    val_acc: %.3f\" % (epoch+1, val_acc, val_loss))\n",
        "\n",
        "\n",
        "# 評価データで性能確認（推定値と目標値を評価データの先頭10件分表示し、評価データの正解率を表示）\n",
        "print(\"出力:\", [\"%d\" % p for p in labels1[:10]])\n",
        "print(\"正解:\", [\"%d\" % p for p in labels2[:10]])\n",
        "train_acc, train_loss = calc_acc(train_loader)\n",
        "print(\"学習データの正解率:\", train_acc)\n",
        "test_acc, test_loss = calc_acc(test_loader)\n",
        "print(\"評価データの正解率:\", test_acc)"
      ],
      "metadata": {
        "id": "wU57cZcrA_jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88b6091-e1fd-434e-d5eb-57cd77280dba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1    val_acc: 0.831    val_acc: 0.461\n",
            "epoch: 2    val_acc: 0.831    val_acc: 0.457\n",
            "epoch: 3    val_acc: 0.833    val_acc: 0.453\n",
            "epoch: 4    val_acc: 0.832    val_acc: 0.449\n",
            "epoch: 5    val_acc: 0.835    val_acc: 0.446\n",
            "epoch: 6    val_acc: 0.835    val_acc: 0.442\n",
            "epoch: 7    val_acc: 0.839    val_acc: 0.439\n",
            "epoch: 8    val_acc: 0.840    val_acc: 0.436\n",
            "epoch: 9    val_acc: 0.840    val_acc: 0.433\n",
            "epoch: 10    val_acc: 0.841    val_acc: 0.430\n",
            "epoch: 11    val_acc: 0.841    val_acc: 0.427\n",
            "epoch: 12    val_acc: 0.844    val_acc: 0.424\n",
            "epoch: 13    val_acc: 0.844    val_acc: 0.421\n",
            "epoch: 14    val_acc: 0.845    val_acc: 0.419\n",
            "epoch: 15    val_acc: 0.845    val_acc: 0.417\n",
            "epoch: 16    val_acc: 0.846    val_acc: 0.414\n",
            "epoch: 17    val_acc: 0.846    val_acc: 0.412\n",
            "epoch: 18    val_acc: 0.846    val_acc: 0.410\n",
            "epoch: 19    val_acc: 0.846    val_acc: 0.408\n",
            "epoch: 20    val_acc: 0.848    val_acc: 0.406\n",
            "epoch: 21    val_acc: 0.849    val_acc: 0.404\n",
            "epoch: 22    val_acc: 0.849    val_acc: 0.402\n",
            "epoch: 23    val_acc: 0.851    val_acc: 0.400\n",
            "epoch: 24    val_acc: 0.852    val_acc: 0.398\n",
            "epoch: 25    val_acc: 0.853    val_acc: 0.396\n",
            "epoch: 26    val_acc: 0.853    val_acc: 0.394\n",
            "epoch: 27    val_acc: 0.853    val_acc: 0.393\n",
            "epoch: 28    val_acc: 0.853    val_acc: 0.391\n",
            "epoch: 29    val_acc: 0.854    val_acc: 0.390\n",
            "epoch: 30    val_acc: 0.855    val_acc: 0.388\n",
            "出力: ['2', '0', '2', '2', '0', '0', '0', '0', '0', '1']\n",
            "正解: ['2', '0', '2', '2', '0', '0', '0', '0', '0', '3']\n",
            "学習データの正解率: tensor(0.8747)\n",
            "評価データの正解率: tensor(0.8429)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 75. 損失と正解率のプロット tensorboardを利用しました。重かったため結果は消しています。\n",
        "# ============\n",
        "%load_ext tensorboard\n",
        "!rm -rf ./runs\n",
        "%tensorboard --logdir ./runs\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "\n",
        "# ラベルを格納するリスト↓\n",
        "labels1 = []\n",
        "labels2 = []\n",
        "\n",
        "# 訓練ループ（エポックごとに検証データの正解率を表示）\n",
        "max_epoch = 30\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for x, t in train_loader:\n",
        "\n",
        "        # データをGPUへ転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 勾配を初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播\n",
        "        y = net(x)   # 2\n",
        "        loss = criterion(y, t)   # 3\n",
        "\n",
        "        # 学習状況の確認\n",
        "        label = torch.argmax(y, dim=1)\n",
        "        acc = (label == t).sum() * 1.0 / len(t)\n",
        "        # print(\"epoch: %d    loss: %.3f    acc: %.3f\" % (epoch+1, loss.item(), acc))\n",
        "\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()   # 4\n",
        "        optimizer.step()  # 5\n",
        "    \n",
        "    # 訓練データの性能を確認\n",
        "    train_acc, train_loss = calc_acc(train_loader)\n",
        "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
        "    \n",
        "    # 検証データの性能を確認\n",
        "    val_acc, val_loss = calc_acc(val_loader)\n",
        "    writer.add_scalar('Loss/valid', val_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/valid', val_acc, epoch)\n",
        "    print(\"epoch: %d    val_acc: %.3f    val_loss: %.3f\" % (epoch+1, val_acc, val_loss))\n",
        "\n",
        "\n",
        "# 評価データで性能確認（推定値と目標値を評価データの先頭10件分表示し、評価データの正解率を表示）\n",
        "print(\"出力:\", [\"%d\" % p for p in labels1[:10]])\n",
        "print(\"正解:\", [\"%d\" % p for p in labels2[:10]])\n",
        "test_acc, test_loss = calc_acc(test_loader)\n",
        "print(\"正解率:\", test_acc)"
      ],
      "metadata": {
        "id": "en7xo-KEA_Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 76. チェックポイント\n",
        "# ============\n",
        "# 保存するディレクトリの作成\n",
        "! rm -r /content/checkpoints\n",
        "! mkdir -p /content/checkpoints\n",
        "\n",
        "# ラベルを格納するリスト↓\n",
        "labels1 = []\n",
        "labels2 = []\n",
        "\n",
        "# 訓練ループ（エポックごとに検証データの正解率を表示）\n",
        "max_epoch = 30\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for x, t in train_loader:\n",
        "\n",
        "        # データをGPUへ転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 勾配を初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播\n",
        "        y = net(x)   # 2\n",
        "        loss = criterion(y, t)   # 3\n",
        "\n",
        "        # 学習状況の確認\n",
        "        label = torch.argmax(y, dim=1)\n",
        "        acc = (label == t).sum() * 1.0 / len(t)\n",
        "        # print(\"epoch: %d    loss: %.3f    acc: %.3f\" % (epoch+1, loss.item(), acc))\n",
        "\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()   # 4\n",
        "        optimizer.step()  # 5\n",
        "    \n",
        "    # 訓練データの性能を確認\n",
        "    train_acc, train_loss = calc_acc(train_loader)\n",
        "\n",
        "    # チェックポイントの保存\n",
        "    torch.save(net.state_dict(), '/content/checkpoints/'+'checkpoint'+str(epoch)+'.model')\n",
        "    torch.save(optimizer.state_dict(), '/content/checkpoints/'+'checkpoint'+str(epoch)+'.param')\n",
        "\n",
        "    \n",
        "    # 検証データの性能を確認\n",
        "    val_acc, val_loss = calc_acc(val_loader)\n",
        "    print(\"epoch: %d    val_acc: %.3f    val_loss: %.3f\" % (epoch+1, val_acc, val_loss))\n",
        "    \n",
        "# 評価データで性能確認（推定値と目標値を評価データの先頭10件分表示し、評価データの正解率を表示）\n",
        "print(\"出力:\", [\"%d\" % p for p in labels1[:10]])\n",
        "print(\"正解:\", [\"%d\" % p for p in labels2[:10]])\n",
        "test_acc, test_loss = calc_acc(test_loader)\n",
        "print(\"正解率:\", test_acc)"
      ],
      "metadata": {
        "id": "PEw9AXN-A_RG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2288a35-4ef6-4ca4-cecf-4c0d978ae130"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/checkpoints': No such file or directory\n",
            "epoch: 1    val_acc: 0.856    val_loss: 0.387\n",
            "epoch: 2    val_acc: 0.856    val_loss: 0.385\n",
            "epoch: 3    val_acc: 0.857    val_loss: 0.384\n",
            "epoch: 4    val_acc: 0.858    val_loss: 0.382\n",
            "epoch: 5    val_acc: 0.860    val_loss: 0.381\n",
            "epoch: 6    val_acc: 0.860    val_loss: 0.380\n",
            "epoch: 7    val_acc: 0.860    val_loss: 0.378\n",
            "epoch: 8    val_acc: 0.863    val_loss: 0.377\n",
            "epoch: 9    val_acc: 0.863    val_loss: 0.376\n",
            "epoch: 10    val_acc: 0.864    val_loss: 0.375\n",
            "epoch: 11    val_acc: 0.865    val_loss: 0.373\n",
            "epoch: 12    val_acc: 0.865    val_loss: 0.372\n",
            "epoch: 13    val_acc: 0.864    val_loss: 0.371\n",
            "epoch: 14    val_acc: 0.865    val_loss: 0.370\n",
            "epoch: 15    val_acc: 0.864    val_loss: 0.369\n",
            "epoch: 16    val_acc: 0.864    val_loss: 0.368\n",
            "epoch: 17    val_acc: 0.864    val_loss: 0.367\n",
            "epoch: 18    val_acc: 0.865    val_loss: 0.366\n",
            "epoch: 19    val_acc: 0.866    val_loss: 0.365\n",
            "epoch: 20    val_acc: 0.867    val_loss: 0.364\n",
            "epoch: 21    val_acc: 0.867    val_loss: 0.363\n",
            "epoch: 22    val_acc: 0.867    val_loss: 0.362\n",
            "epoch: 23    val_acc: 0.867    val_loss: 0.361\n",
            "epoch: 24    val_acc: 0.868    val_loss: 0.360\n",
            "epoch: 25    val_acc: 0.868    val_loss: 0.359\n",
            "epoch: 26    val_acc: 0.868    val_loss: 0.358\n",
            "epoch: 27    val_acc: 0.868    val_loss: 0.357\n",
            "epoch: 28    val_acc: 0.868    val_loss: 0.357\n",
            "epoch: 29    val_acc: 0.869    val_loss: 0.356\n",
            "epoch: 30    val_acc: 0.869    val_loss: 0.355\n",
            "出力: ['0', '1', '0', '2', '2', '2', '2', '2', '2', '2']\n",
            "正解: ['0', '1', '0', '2', '2', '2', '2', '2', '2', '2']\n",
            "正解率: tensor(0.8623)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 77. ミニバッチ化 \n",
        "# ============\n",
        "\"\"\"\n",
        "ミニバッチ化の機能はすでにあるのでバッチサイズのみ変えて学習を行う\n",
        "\"\"\"\n",
        "# ランダムシード\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# バッチサイズ\n",
        "batch_size = 32\n",
        "\n",
        "# 損失関数と最適化手法の選択\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
        "\n",
        "# 訓練用・検証用・評価用の各データをDataLoaderに格納\n",
        "train_loader = DataLoader(train, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(valid, batch_size)\n",
        "test_loader = DataLoader(test, batch_size)\n",
        "\n",
        "# 保存するディレクトリの作成\n",
        "# ! mkdir -p /content/checkpoints\n",
        "\n",
        "# ラベルを格納するリスト↓\n",
        "labels1 = []\n",
        "labels2 = []\n",
        "\n",
        "# 訓練ループ（エポックごとに検証データの正解率を表示）\n",
        "max_epoch = 30\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for x, t in train_loader:\n",
        "\n",
        "        # データをGPUへ転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 勾配を初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播\n",
        "        y = net(x)   # 2\n",
        "        loss = criterion(y, t)   # 3\n",
        "\n",
        "        # 学習状況の確認\n",
        "        label = torch.argmax(y, dim=1)\n",
        "        acc = (label == t).sum() * 1.0 / len(t)\n",
        "        # print(\"epoch: %d    loss: %.3f    acc: %.3f\" % (epoch+1, loss.item(), acc))\n",
        "\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()   # 4\n",
        "        optimizer.step()  # 5\n",
        "    \n",
        "    # 訓練データの性能を確認\n",
        "    train_acc, train_loss = calc_acc(train_loader)\n",
        "\n",
        "    # チェックポイントの保存\n",
        "    # torch.save(net.state_dict(), '/content/checkpoints/'+'checkpoint'+str(epoch)+'.model')\n",
        "    # torch.save(optimizer.state_dict(), '/content/checkpoints/'+'checkpoint'+str(epoch)+'.param')\n",
        "\n",
        "    \n",
        "    # 検証データの性能を確認\n",
        "    val_acc, val_loss = calc_acc(val_loader)\n",
        "    print(\"epoch: %d    val_acc: %.3f    val_loss: %.3f\" % (epoch+1, val_acc, val_loss))\n",
        "\n",
        "# 評価データで性能確認（推定値と目標値を評価データの先頭10件分表示し、評価データの正解率を表示）\n",
        "print(\"出力:\", [\"%d\" % p for p in labels1[:10]])\n",
        "print(\"正解:\", [\"%d\" % p for p in labels2[:10]])\n",
        "test_acc, test_loss = calc_acc(test_loader)\n",
        "print(\"正解率:\", test_acc)"
      ],
      "metadata": {
        "id": "Rtb0QuJSA_Hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16c12cb-7fcb-44e2-be28-641de04a957a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1    val_acc: 0.901    val_loss: 0.275\n",
            "epoch: 2    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 3    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 4    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 5    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 6    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 7    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 8    val_acc: 0.901    val_loss: 0.275\n",
            "epoch: 9    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 10    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 11    val_acc: 0.899    val_loss: 0.275\n",
            "epoch: 12    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 13    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 14    val_acc: 0.899    val_loss: 0.275\n",
            "epoch: 15    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 16    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 17    val_acc: 0.902    val_loss: 0.275\n",
            "epoch: 18    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 19    val_acc: 0.899    val_loss: 0.275\n",
            "epoch: 20    val_acc: 0.901    val_loss: 0.275\n",
            "epoch: 21    val_acc: 0.901    val_loss: 0.274\n",
            "epoch: 22    val_acc: 0.899    val_loss: 0.275\n",
            "epoch: 23    val_acc: 0.899    val_loss: 0.275\n",
            "epoch: 24    val_acc: 0.901    val_loss: 0.274\n",
            "epoch: 25    val_acc: 0.901    val_loss: 0.274\n",
            "epoch: 26    val_acc: 0.901    val_loss: 0.274\n",
            "epoch: 27    val_acc: 0.901    val_loss: 0.274\n",
            "epoch: 28    val_acc: 0.900    val_loss: 0.275\n",
            "epoch: 29    val_acc: 0.901    val_loss: 0.274\n",
            "epoch: 30    val_acc: 0.901    val_loss: 0.274\n",
            "出力: ['2', '2', '0', '1', '0', '0', '2', '3', '2', '0']\n",
            "正解: ['2', '2', '0', '1', '0', '0', '2', '0', '2', '0']\n",
            "正解率: tensor(0.9037)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 78. GPU上での学習\n",
        "# ============\n",
        "\"\"\"\n",
        "すでにGPU上で学習をしていたためスキップ\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WYfaAeLAA--c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============\n",
        "# 79. 多層ニューラルネットワーク\n",
        "# ============\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(300, 64)\n",
        "        self.fc2 = nn.Linear(64, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = F.relu(self.fc1(x))  # xを線形変換（fc1）し、非線形変換（relu）し、中間表現hを得る\n",
        "        y = self.fc2(h)\n",
        "        return y\n",
        "\n",
        "# ネットワークのインスタンスを作成\n",
        "net = Net() \n",
        "\n",
        "# バッチサイズ\n",
        "batch_size = 32\n",
        "\n",
        "# 訓練用・検証用・評価用の各データをDataLoaderに格納\n",
        "train_loader = DataLoader(train, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(valid, batch_size)\n",
        "test_loader = DataLoader(test, batch_size)\n",
        "\n",
        "# 損失関数と最適化手法の選択\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
        "\n",
        "# モデルをGPUへ転送\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = net.to(device)\n",
        "\n",
        "# バッチサイズ\n",
        "batch_size = 64\n",
        "\n",
        "# 保存するディレクトリの作成\n",
        "# ! mkdir -p /content/checkpoints\n",
        "\n",
        "# ラベルを格納するリスト↓\n",
        "labels1 = []\n",
        "labels2 = []\n",
        "\n",
        "def calc_acc(data_loader):\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "        accs = list()\n",
        "        for x, t in data_loader:\n",
        "            x = x.to(device)\n",
        "            t = t.to(device)\n",
        "            labels2.extend(t)\n",
        "\n",
        "            y = net(x)\n",
        "            loss += criterion(y, t).item()\n",
        "\n",
        "            label = torch.argmax(y, dim=1)\n",
        "            labels1.extend(label)\n",
        "            \n",
        "            acc = (label == t).sum() * 1.0 / len(t)\n",
        "            accs.append(acc)\n",
        "\n",
        "    return torch.tensor(accs).mean(), loss/len(data_loader)\n",
        "\n",
        "# 訓練ループ（エポックごとに検証データの正解率を表示）\n",
        "max_epoch = 20\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for x, t in train_loader:\n",
        "\n",
        "        # データをGPUへ転送\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 勾配を初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 順伝播\n",
        "        y = net(x)   # 2\n",
        "        loss = criterion(y, t)   # 3\n",
        "\n",
        "        # 学習状況の確認\n",
        "        label = torch.argmax(y, dim=1)\n",
        "        acc = (label == t).sum() * 1.0 / len(t)\n",
        "        # print(\"epoch: %d    loss: %.3f    acc: %.3f\" % (epoch+1, loss.item(), acc))\n",
        "\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()   # 4\n",
        "        optimizer.step()  # 5\n",
        "    \n",
        "    # 訓練データの性能を確認\n",
        "    train_acc, train_loss = calc_acc(train_loader)\n",
        "\n",
        "    # チェックポイントの保存\n",
        "    # torch.save(net.state_dict(), '/content/checkpoints/'+'checkpoint'+str(epoch)+'.model')\n",
        "    # torch.save(optimizer.state_dict(), '/content/checkpoints/'+'checkpoint'+str(epoch)+'.param')\n",
        "\n",
        "    \n",
        "    # 検証データの性能を確認\n",
        "    val_acc, val_loss = calc_acc(val_loader)\n",
        "    print(\"epoch: %d    val_acc: %.3f    val_acc: %.3f\" % (epoch+1, val_acc, val_loss))\n",
        "\n",
        "# 評価データで性能確認（推定値と目標値を評価データの先頭10件分表示し、評価データの正解率を表示）\n",
        "print(\"出力:\", [\"%d\" % p for p in labels1[:10]])\n",
        "print(\"正解:\", [\"%d\" % p for p in labels2[:10]])\n",
        "test_acc, test_loss = calc_acc(test_loader)\n",
        "print(\"正解率:\", test_acc)"
      ],
      "metadata": {
        "id": "d6Y0clP0A-y3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8198172-b3dd-478f-8321-2323018e9268"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1    val_acc: 0.771    val_acc: 0.780\n",
            "epoch: 2    val_acc: 0.774    val_acc: 0.594\n",
            "epoch: 3    val_acc: 0.794    val_acc: 0.526\n",
            "epoch: 4    val_acc: 0.820    val_acc: 0.470\n",
            "epoch: 5    val_acc: 0.853    val_acc: 0.420\n",
            "epoch: 6    val_acc: 0.874    val_acc: 0.379\n",
            "epoch: 7    val_acc: 0.880    val_acc: 0.349\n",
            "epoch: 8    val_acc: 0.886    val_acc: 0.334\n",
            "epoch: 9    val_acc: 0.893    val_acc: 0.317\n",
            "epoch: 10    val_acc: 0.894    val_acc: 0.302\n",
            "epoch: 11    val_acc: 0.892    val_acc: 0.297\n",
            "epoch: 12    val_acc: 0.895    val_acc: 0.291\n",
            "epoch: 13    val_acc: 0.900    val_acc: 0.283\n",
            "epoch: 14    val_acc: 0.899    val_acc: 0.288\n",
            "epoch: 15    val_acc: 0.901    val_acc: 0.277\n",
            "epoch: 16    val_acc: 0.906    val_acc: 0.274\n",
            "epoch: 17    val_acc: 0.897    val_acc: 0.276\n",
            "epoch: 18    val_acc: 0.906    val_acc: 0.272\n",
            "epoch: 19    val_acc: 0.909    val_acc: 0.269\n",
            "epoch: 20    val_acc: 0.903    val_acc: 0.275\n",
            "出力: ['2', '2', '2', '2', '2', '2', '2', '2', '0', '2']\n",
            "正解: ['2', '2', '2', '2', '3', '0', '2', '2', '0', '1']\n",
            "正解率: tensor(0.9007)\n"
          ]
        }
      ]
    }
  ]
}